{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dswh/lil_nlp_with_tensorflow/blob/main/01_05_challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHhTfLI0AkGw"
   },
   "source": [
    "# Sentiment Analysis - Tokenizing news headlines for data preparation!\n",
    "The notebook covers the data preparation step by tokenizing the headlines and creating padded sequences of news headlines.\n",
    "\n",
    "Data preparation include the following steps:\n",
    "1. Download and read the data\n",
    "2. Segregate the headlines and their labels.\n",
    "3. Tokenize the headlines\n",
    "4. Create sequences and add padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8n1m0nTJ2YZk"
   },
   "source": [
    "## 1. Download and read the news headlines data\n",
    "\n",
    "This is a [kaggle dataset](https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection) which is further corrected and then hosted on Google Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NVL_lt3eV6QG"
   },
   "outputs": [],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/wdd-2-node.appspot.com/x1.json \\\n",
    "    -o /tmp/headlines.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "nDDtuZMxFL45",
    "outputId": "eef7a7d6-46e6-42d0-e423-0ec7bc027848"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic  ...                                       article_link\n",
       "0             1  ...  https://www.theonion.com/thirtysomething-scien...\n",
       "1             0  ...  https://www.huffingtonpost.com/entry/donna-edw...\n",
       "2             0  ...  https://www.huffingtonpost.com/entry/eat-your-...\n",
       "3             1  ...  https://local.theonion.com/inclement-weather-p...\n",
       "4             1  ...  https://www.theonion.com/mother-comes-pretty-c...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##read the data using the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_json(\"./x1.json\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qM32g4_bB164"
   },
   "source": [
    "## Segregating the headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U94MLAY4Op-R"
   },
   "outputs": [],
   "source": [
    "##create lists to store the headlines and labels\n",
    "headlines = list(data['headline'])\n",
    "labels = list(data['is_sarcastic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rx6EJudWB4lr"
   },
   "source": [
    "## Import the APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utD9B6ebgWtn"
   },
   "outputs": [],
   "source": [
    "##import the required APIs\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MOcIxz52PJg"
   },
   "source": [
    "## 3. Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nD9vBy7hiEt"
   },
   "outputs": [],
   "source": [
    "##set up the tokenizer\n",
    "tokenizer = Tokenizer(oov_token=\"____\")\n",
    "tokenizer.fit_on_texts(____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qyl2AvkEhmhK"
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.____\n",
    "print(word_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wr2GdrA62TxP"
   },
   "source": [
    "## 4. Create padded sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFhaOb5ohvNA"
   },
   "outputs": [],
   "source": [
    "##create sequences of the headlines\n",
    "seqs = tokenizer.____(____)\n",
    "\n",
    "##post-pad sequences\n",
    "padded_seqs = ____(____, padding=\"____\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOgjRP1YiNxn"
   },
   "outputs": [],
   "source": [
    "##printing padded sequences sample\n",
    "print(____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAbu3ReZiRJc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPETKNiYZsFvcC215GAp9SV",
   "include_colab_link": true,
   "name": "01_05_challenge.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
